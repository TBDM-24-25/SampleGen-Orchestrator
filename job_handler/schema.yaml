# If no image is provided, the job will be executed with a default image for this data type.
data_type: temperature
topic: temperature
# No need for Kafka host/port here
# The job handler will use the Kafka host/port from the configuration file
container_image_name: "temperature-simulator"
container_registry:
  url: "gcr.io/my-project/temperature-simulator:latest" # this should also include the tag if required. For eample, myregistry.azurecr.io/my-repo/my-image:latest
  type: private
  user_credentials:
    username: "username"
    password: "password"
    token: "token" # Can be used instead of username and password
computation_duration_in_seconds: 3600
# Can be defined via parameters when the image is started. See documentation https://docs.docker.com/reference/cli/docker/container/run/
resource_limits:
  cpu: 1.0
  memory: 1Gi
# If the container nodes fail, the job follows the retry policy with the goal of successful execution.
retry_policy:
  retry_on_failure: true
  number_of_retries: 3
  backoff_period_in_ms: 10
# Can be defined via parameters when the image is started. See documentation https://docs.docker.com/reference/cli/docker/container/run/
ports:
  host_port: 8080
  container_port: 80
# Can be defined via parameters when the image is started. See documentation https://docs.docker.com/reference/cli/docker/container/run/
# Could be useful if additional environment variables are required for the image to run.
environment_variables:
  - name: PYTHON_VERSION
    value: "3.7"
  - name: SPARK_VERSION
    value: "3.0.0"
# Supports tracablity of the job.
metadata:
  user: "user"
  job_id: "job_id"
  created_at: "2024-11-27T10:00:00Z"
  requested_at: "2024-11-27T10:00:00Z"
  run_at: "2024-11-27T10:00:00Z"
  description: "This job generates temperature data for IoT simulation."
  # Connection stream not required in schema since it is already defined in the configuration file. Only makes sense for multiple Kafka clusters.